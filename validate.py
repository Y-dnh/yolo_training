"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è/–≤–∞–ª—ñ–¥–∞—Ü—ñ—ó YOLO / RT-DETR –º–æ–¥–µ–ª—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó –Ω–∞ IR –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö.
–£—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –Ω–∞ –ø–æ—á–∞—Ç–∫—É —Ñ–∞–π–ª—É.

–ü–µ—Ä–µ–º–∏–∫–∞—á MODEL_TYPE –¥–æ–∑–≤–æ–ª—è—î –æ–±—Ä–∞—Ç–∏ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É:
  - "yolo"   -> ultralytics.YOLO
  - "rtdetr"  -> ultralytics.RTDETR
"""

import os
import json
from pathlib import Path
from datetime import datetime
import torch
from ultralytics import YOLO, RTDETR


# =============================================================================
# –í–ò–ë–Ü–† –ê–†–•–Ü–¢–ï–ö–¢–£–†–ò: "yolo" –∞–±–æ "rtdetr"
# =============================================================================
VALID_MODEL_TYPES = {"yolo", "rtdetr"}
MODEL_TYPE = "yolo"        # <-- –ü–ï–†–ï–ú–ò–ö–ê–ß: "yolo" –∞–±–æ "rtdetr"

# =============================================================================
# –ü–ê–†–ê–ú–ï–¢–†–ò, –°–ü–ï–¶–ò–§–Ü–ß–ù–Ü –î–õ–Ø –ö–û–ñ–ù–û–á –ê–†–•–Ü–¢–ï–ö–¢–£–†–ò (–≤–∞–ª—ñ–¥–∞—Ü—ñ—è)
# =============================================================================

# –ö–ª—é—á—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó, —è–∫—ñ —î –¢–Ü–õ–¨–ö–ò —É YOLO
YOLO_ONLY_VAL_KEYS = {
    "agnostic_nms",     # Class-agnostic NMS ‚Äî RT-DETR –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î NMS
    "dnn",              # OpenCV DNN backend ‚Äî —Ç—ñ–ª—å–∫–∏ –¥–ª—è YOLO
}

# –ö–ª—é—á—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó, —è–∫—ñ —î –¢–Ü–õ–¨–ö–ò —É RT-DETR
RTDETR_ONLY_VAL_KEYS: set[str] = set()

# =============================================================================
# –ë–ê–ó–û–í–ê –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø
# =============================================================================
PROJECT_NAME = "yolov8x-p2_for_autolabelling"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.join(BASE_DIR, PROJECT_NAME)
DATASET_ROOT = os.path.join(BASE_DIR, "dataset_split")
YAML_PATH = os.path.join(DATASET_ROOT, "yolo.yaml")
EXPERIMENT_NAME = "validation_test_960"

TRAINED_MODEL_PATH = os.path.join(PROJECT_DIR, "baseline", "weights", "best.pt")

# –ö–ª–∞—Å–∏ –¥–∞—Ç–∞—Å–µ—Ç—É
CLASSES = {
    0: "person",
    1: "car",
    2: "truck",
}


# =============================================================================
# –ü–ê–†–ê–ú–ï–¢–†–ò –í–ê–õ–Ü–î–ê–¶–Ü–á (–ø–µ—Ä–µ–¥–∞—é—Ç—å—Å—è —è–∫ **kwargs –¥–æ model.val())
# =============================================================================
VALIDATION_CONFIG = {
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–∞—Ç–∞—Å–µ—Ç—É
    "data": YAML_PATH,
    "split": "test",
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–µ—Ç–µ–∫—Ü—ñ—ó
    "conf": 0.5,
    "iou": 0.5,
    "imgsz": 960,
    "device": None,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è
    "batch": 32,  # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ
    "max_det": 300,
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –æ–±—Ä–æ–±–∫–∏
    "rect": True,
    "half": True,
    "augment": False,
    "agnostic_nms": False,   # [YOLO-only] RT-DETR –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î NMS
    "classes": None,
    "single_cls": False,
    "dnn": False,
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤–∏–≤–æ–¥—É
    "save_json": True,
    "save_txt": False,
    "save_conf": True,
    "plots": True,
    "verbose": False,
    "workers": 8,  # 0 —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ multiprocessing —Ç–∞ –ø—Ä–æ–±–ª–µ–º –∑ –ø–∞–º'—è—Ç—Ç—é
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    "visualize": True,
    
    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É
    "project": PROJECT_DIR,
    "name": EXPERIMENT_NAME,
}


def validate_model_type() -> None:
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —â–æ MODEL_TYPE –º–∞—î –¥–æ–ø—É—Å—Ç–∏–º–µ –∑–Ω–∞—á–µ–Ω–Ω—è."""
    if MODEL_TYPE not in VALID_MODEL_TYPES:
        raise ValueError(
            f"–ù–µ–≤—ñ–¥–æ–º–∏–π MODEL_TYPE: '{MODEL_TYPE}'. "
            f"–î–æ–ø—É—Å—Ç–∏–º—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: {sorted(VALID_MODEL_TYPES)}"
        )


def load_model(model_path: str):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ MODEL_TYPE.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø, —è–∫—â–æ –≤ —à–ª—è—Ö—É —î 'rtdetr'.
    
    Args:
        model_path: –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ
    
    Returns:
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å (YOLO –∞–±–æ RTDETR)
    
    Raises:
        ValueError: –Ø–∫—â–æ MODEL_TYPE –Ω–µ–≤—ñ–¥–æ–º–∏–π
    """
    validate_model_type()

    if MODEL_TYPE == "rtdetr" or "rtdetr" in model_path.lower():
        print(f"[Model] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è RT-DETR: {model_path}")
        return RTDETR(model_path)
    else:
        print(f"[Model] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è YOLO: {model_path}")
        return YOLO(model_path)


def filter_config(config: dict, excluded_keys: set) -> dict:
    """
    –§—ñ–ª—å—Ç—Ä—É—î –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é: –≤–∏–¥–∞–ª—è—î –∫–ª—é—á—ñ, –Ω–µ—Å—É–º—ñ—Å–Ω—ñ –∑ –ø–æ—Ç–æ—á–Ω–æ—é –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é.
    
    Args:
        config: –í—Ö—ñ–¥–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
        excluded_keys: –ú–Ω–æ–∂–∏–Ω–∞ –∫–ª—é—á—ñ–≤, —è–∫—ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–¥–∞–ª–∏—Ç–∏
    
    Returns:
        dict: –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫
    """
    removed = set(config.keys()) & excluded_keys
    if removed:
        print(f"[Config] MODEL_TYPE='{MODEL_TYPE}' -> –≤–∏–¥–∞–ª–µ–Ω–æ –Ω–µ—Å—É–º—ñ—Å–Ω—ñ –∫–ª—é—á—ñ: {sorted(removed)}")

    return {k: v for k, v in config.items() if k not in excluded_keys}


def get_val_config(**kwargs) -> dict:
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏–π validation config –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ MODEL_TYPE.
    
    Args:
        **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏, —â–æ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—é—Ç—å VALIDATION_CONFIG
    
    Returns:
        dict: –ì–æ—Ç–æ–≤–∏–π –∫–æ–Ω—Ñ—ñ–≥ –¥–ª—è model.val()
    """
    config = {**VALIDATION_CONFIG, **kwargs}

    if MODEL_TYPE == "rtdetr":
        return filter_config(config, YOLO_ONLY_VAL_KEYS)
    elif MODEL_TYPE == "yolo":
        return filter_config(config, RTDETR_ONLY_VAL_KEYS)
    return config


def print_header(model_path: str, config: dict, device: str) -> None:
    """–í–∏–≤–µ–¥–µ–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫—É –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó."""
    model_name = Path(model_path).name
    print()
    print("=" * 70)
    print("YOLO VALIDATION")
    print("=" * 70)
    print(f"Model: {model_name}")
    print(f"Dataset: {config['data']}")
    print(f"Split: {config['split']}")
    print(f"Image Size: {config['imgsz']}")
    print(f"Conf threshold: {config['conf']}")
    print(f"IoU threshold: {config['iou']}")
    print(f"Max detections: {config['max_det']}")
    print(f"Half (FP16): {config['half']}")
    print(f"Device: {device}")
    print("=" * 70)
    print()


def setup_device() -> str:
    """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –ø—Ä–∏—Å—Ç—Ä–æ—é."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return device


def validate_model(
    model_path: str = TRAINED_MODEL_PATH,
    **kwargs
) -> object:
    """
    –í–∞–ª—ñ–¥–∞—Ü—ñ—è YOLO –º–æ–¥–µ–ª—ñ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ.
    
    Args:
        model_path: –®–ª—è—Ö –¥–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—é—Ç—å VALIDATION_CONFIG)
    
    Returns:
        object: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    """
    # –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏–π –∫–æ–Ω—Ñ—ñ–≥ –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ MODEL_TYPE
    config = get_val_config(**kwargs)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è device —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ
    if config["device"] is None:
        config["device"] = setup_device()
    
    # –í–∏–≤–æ–¥–∏–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    print_header(model_path, config, config["device"])
    
    print(f"[Validator] Loading {MODEL_TYPE.upper()} model from {Path(model_path).name}...")
    model = load_model(model_path)
    print(f"[Validator] Model loaded successfully!")
    
    # –ó–∞–ø—É—Å–∫ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    results = model.val(**config)
    
    return results


def extract_metrics(validation_results: object) -> dict:
    """
    –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    
    Args:
        validation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –≤—ñ–¥ model.val()
    
    Returns:
        dict: –°–ª–æ–≤–Ω–∏–∫ –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    precision = float(validation_results.box.mp) if hasattr(validation_results.box, "mp") else 0.0
    recall = float(validation_results.box.mr) if hasattr(validation_results.box, "mr") else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    metrics = {
        # –û—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
        "mAP50": float(validation_results.box.map50) if hasattr(validation_results.box, "map50") else 0.0,
        "mAP50-95": float(validation_results.box.map) if hasattr(validation_results.box, "map") else 0.0,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }
    
    # Per-class —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    class_stats = {}
    if hasattr(validation_results.box, "maps") and validation_results.box.maps is not None:
        maps = validation_results.box.maps
        for i, (class_id, class_name) in enumerate(CLASSES.items()):
            if i < len(maps):
                stat = {"mAP50": float(maps[i]) if maps[i] is not None else 0.0}
                if hasattr(validation_results.box, "p") and validation_results.box.p is not None:
                    if i < len(validation_results.box.p):
                        stat["precision"] = float(validation_results.box.p[i])
                if hasattr(validation_results.box, "r") and validation_results.box.r is not None:
                    if i < len(validation_results.box.r):
                        stat["recall"] = float(validation_results.box.r[i])
                class_stats[str(class_id)] = stat
    
    metrics["class_stats"] = class_stats
    
    return metrics


def get_speed_info(validation_results: object) -> dict:
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ —à–≤–∏–¥–∫—ñ—Å—Ç—å."""
    speed_info = {}
    if hasattr(validation_results, "speed"):
        speed = validation_results.speed
        speed_info = {
            "preprocess_ms": speed.get("preprocess", 0),
            "inference_ms": speed.get("inference", 0),
            "postprocess_ms": speed.get("postprocess", 0),
        }
        total_time = sum(speed_info.values())
        speed_info["total_ms"] = total_time
        speed_info["fps"] = round(1000 / total_time, 2) if total_time > 0 else 0
    return speed_info


def save_results_json(
    metrics: dict,
    speed_info: dict,
    model_path: str,
    output_dir: str
) -> str:
    """
    –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É —î–¥–∏–Ω–∏–π JSON —Ñ–∞–π–ª.
    
    Args:
        metrics: –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        speed_info: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —à–≤–∏–¥–∫—ñ—Å—Ç—å
        model_path: –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    
    Returns:
        str: –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    """
    results = {
        "metrics": {
            "mAP50": metrics["mAP50"],
            "mAP50-95": metrics["mAP50-95"],
            "precision": metrics["precision"],
            "recall": metrics["recall"],
            "f1": metrics["f1"],
            "class_stats": metrics.get("class_stats", {}),
        },
        "num_classes": len(CLASSES),
        "classes": list(CLASSES.values()),
        "inference_fps": speed_info.get("fps", 0),
        "inference_latency_ms": speed_info.get("total_ms", 0),
        "split": VALIDATION_CONFIG["split"],
        "dataset_dir": DATASET_ROOT,
        "validation_date": datetime.now().isoformat(),
        "inference_config": {
            "conf_threshold": VALIDATION_CONFIG["conf"],
            "iou_threshold": VALIDATION_CONFIG["iou"],
            "max_det": VALIDATION_CONFIG["max_det"],
            "classes": VALIDATION_CONFIG["classes"],
            "agnostic_nms": VALIDATION_CONFIG["agnostic_nms"],
            "half": VALIDATION_CONFIG["half"],
            "batch_size": VALIDATION_CONFIG["batch"],
            "imgsz": VALIDATION_CONFIG["imgsz"],
            "workers": VALIDATION_CONFIG["workers"],
            "device": VALIDATION_CONFIG["device"] or "cuda",
        },
        "model_path": model_path,
    }
    
    json_path = os.path.join(output_dir, "validation_results.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    return json_path


def generate_markdown_report(
    metrics: dict,
    speed_info: dict,
    model_path: str,
    output_dir: str
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ markdown –∑–≤—ñ—Ç—É.
    
    Args:
        metrics: –°–ª–æ–≤–Ω–∏–∫ –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        speed_info: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —à–≤–∏–¥–∫—ñ—Å—Ç—å
        model_path: –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É
    
    Returns:
        str: –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ –∑–≤—ñ—Ç—É
    """
    model_name = Path(model_path).stem
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # –§–æ—Ä–º—É—î–º–æ –∑–≤—ñ—Ç —É —Ñ–æ—Ä–º–∞—Ç—ñ —è–∫ —É –ø—Ä–∏–∫–ª–∞–¥—ñ
    report_content = f"""# üéØ YOLO Validation Report

## Experiment Overview

| **Parameter** | **Value** |
|---------------|-----------|
| **Model** | `{model_name}` |
| **Model Path** | `{model_path}` |
| **Date & Time** | {current_time} |
| **Dataset** | `{DATASET_ROOT}` |
| **Split** | `{VALIDATION_CONFIG['split']}` |
| **Object Categories** | {len(CLASSES)} |

## Configuration Settings

| **Setting** | **Value** |
|-------------|-----------|
| **Confidence Threshold** | {VALIDATION_CONFIG['conf']} |
| **IoU Threshold** | {VALIDATION_CONFIG['iou']} |
| **Image Size** | {VALIDATION_CONFIG['imgsz']} |
| **Batch Size** | {VALIDATION_CONFIG['batch']} |
| **Half (FP16)** | {VALIDATION_CONFIG['half']} |
| **Device** | {VALIDATION_CONFIG['device'] or 'cuda'} |

---

## üìä Overall Performance

| **Metric** | **Value** |
|------------|-----------|
| **mAP@0.5** | {metrics['mAP50']:.4f} |
| **mAP@0.5:0.95** | {metrics['mAP50-95']:.4f} |
| **Precision** | {metrics['precision']:.4f} |
| **Recall** | {metrics['recall']:.4f} |
| **F1 Score** | {metrics['f1']:.4f} |

---

## üìã Per-Class Performance

| **Class** | **mAP@0.5** | **Precision** | **Recall** |
|-----------|-------------|---------------|------------|
"""
    
    # –î–æ–¥–∞—î–º–æ per-class –º–µ—Ç—Ä–∏–∫–∏
    class_stats = metrics.get("class_stats", {})
    for class_id, class_name in CLASSES.items():
        stat = class_stats.get(str(class_id), {})
        mAP = stat.get("mAP50", 0)
        prec = stat.get("precision", 0)
        rec = stat.get("recall", 0)
        report_content += f"| {class_name} | {mAP:.4f} | {prec:.4f} | {rec:.4f} |\n"
    
    report_content += f"""
---

## ‚ö° Inference Speed

| **Metric** | **Value** |
|------------|-----------|
| **FPS** | {speed_info.get('fps', 0):.1f} |
| **Latency** | {speed_info.get('total_ms', 0):.2f} ms/image |
| **Preprocess** | {speed_info.get('preprocess_ms', 0):.2f} ms |
| **Inference** | {speed_info.get('inference_ms', 0):.2f} ms |
| **Postprocess** | {speed_info.get('postprocess_ms', 0):.2f} ms |

---

*üìä Report generated by YOLO Validation System*  
*üïê {current_time}*
"""
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–≤—ñ—Ç
    report_path = os.path.join(output_dir, "validation_report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    return report_path


def print_summary(metrics: dict, speed_info: dict, json_path: str, report_path: str) -> None:
    """–í–∏–≤–µ–¥–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É —É –∫–æ–Ω—Å–æ–ª—å."""
    print()
    print(f"üìä Inference Speed: {speed_info.get('fps', 0):.1f} FPS ({speed_info.get('total_ms', 0):.2f} ms/image)")
    print()
    print("=" * 50)
    print("YOLO VALIDATION SUMMARY")
    print("=" * 50)
    print(f"mAP@0.5:      {metrics['mAP50']:.4f}")
    print(f"mAP@0.5:0.95: {metrics['mAP50-95']:.4f}")
    print(f"Precision:    {metrics['precision']:.4f}")
    print(f"Recall:       {metrics['recall']:.4f}")
    print(f"F1 Score:     {metrics['f1']:.4f}")
    print(f"JSON Results: {json_path}")
    print(f"MD Report:    {report_path}")
    print("=" * 50)
    print()
    print(f"[Results] –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {json_path}")


def save_results(
    validation_results: object,
    metrics: dict,
    model_path: str = TRAINED_MODEL_PATH,
    output_dir: str = None
) -> dict:
    """
    –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    
    Args:
        validation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        metrics: –í–∏—Ç—è–≥–Ω—É—Ç—ñ –º–µ—Ç—Ä–∏–∫–∏
        model_path: –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ (–¥–ª—è –∑–≤—ñ—Ç—É)
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    
    Returns:
        dict: –°–ª–æ–≤–Ω–∏–∫ –∑—ñ —à–ª—è—Ö–∞–º–∏ –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
    """
    if output_dir is None:
        output_dir = os.path.join(PROJECT_DIR, EXPERIMENT_NAME)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —à–≤–∏–¥–∫—ñ—Å—Ç—å
    speed_info = get_speed_info(validation_results)
    
    saved_files = {}
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É —î–¥–∏–Ω–∏–π JSON —Ñ–∞–π–ª
    json_path = save_results_json(metrics, speed_info, model_path, output_dir)
    saved_files["validation_json"] = json_path
    
    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è markdown –∑–≤—ñ—Ç—É
    report_path = generate_markdown_report(metrics, speed_info, model_path, output_dir)
    saved_files["markdown_report"] = report_path
    
    # –í–∏–≤–µ–¥–µ–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—É
    print_summary(metrics, speed_info, json_path, report_path)
    
    return saved_files


def main(
    model_path: str = TRAINED_MODEL_PATH,
    save_results_flag: bool = True,
    **kwargs
):
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø—É—Å–∫—É –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    
    Args:
        model_path: –®–ª—è—Ö –¥–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        save_results_flag: –ß–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É —Ñ–∞–π–ª–∏
        **kwargs: –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    """
    # –ó–∞–ø—É—Å–∫ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    results = validate_model(model_path=model_path, **kwargs)
    
    # –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
    metrics = extract_metrics(results)
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    if save_results_flag:
        save_results(results, metrics, model_path=model_path)
    
    return results, metrics


if __name__ == "__main__":
    main()
